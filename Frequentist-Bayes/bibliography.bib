@article{Ioannidis2005,
abstract = {Published research findings are sometimes refuted by subsequent evidence, says Ioannidis, with ensuing confusion and disappointment.},
author = {Ioannidis, John P A},
file = {:H$\backslash$:/References/Ioannidis 2005 - PLOS Medicine\_ Why Most Published Research Findings Are False.pdf:pdf},
journal = {PLoS Med},
month = aug,
number = {8},
pages = {e124},
publisher = {Public Library of Science},
title = {{Why Most Published Research Findings Are False}},
url = {http://dx.doi.org/10.1371\%2Fjournal.pmed.0020124},
volume = {2},
year = {2005}
}

@book{Silver2013,
author = {Silver, Nate},
isbn = {978-0141975658},
keywords = {Bayes,prediction},
mendeley-tags = {prediction,Bayes},
pages = {544},
publisher = {Penguin},
title = {{The Signal and the Noise: the Art and Science of Prediction}},
year = {2013}
}

@article{Jager2013,
abstract = {The accuracy of published medical research is critical both for scientists, physicians and patients who rely on these results. But the fundamental belief in the medical literature was called into serious question by a paper suggesting most published medical research is false. Here we adapt estimation methods from the genomics community to the problem of estimating the rate of false positives in the medical literature using reported P-values as the data. We then collect P-values from the abstracts of all 77,430 papers published in The Lancet, The Journal of the American Medical Association, The New England Journal of Medicine, The British Medical Journal, and The American Journal of Epidemiology between 2000 and 2010. We estimate that the overall rate of false positives among reported results is 14{\%} (s.d. 1{\%}), contrary to previous claims. We also find there is not a significant increase in the estimated rate of reported false positive results over time (0.5{\%} more FP per year, P = 0.18) or with respect to journal submissions (0.1{\%} more FP per 100 submissions, P = 0.48). Statistical analysis must allow for false positives in order to make claims on the basis of noisy data. But our analysis suggests that the medical literature remains a reliable record of scientific progress.},
archivePrefix = {arXiv},
arxivId = {1301.3718},
author = {Jager, Leah R. and Leek, Jeffrey T.},
doi = {10.1093/biostatistics/SWFDR},
eprint = {1301.3718},
journal = {Arxiv preprint},
pages = {11},
title = {{Empirical estimates suggest most published medical research is true}},
url = {http://arxiv.org/abs/1301.3718},
year = {2013}
}

@misc{Leek2012,
author = {Leek, Jeff and Irizarry, Rafa},
booktitle = {Simply Statistics},
keywords = {p-value,statistic},
mendeley-tags = {p-value,statistic},
title = {{P-values and hypothesis testing get a bad rap â€“ but we sometimes find them useful.}},
url = {http://simplystatistics.org/2012/01/06},
urldate = {2015-12-07},
year = {2012}
}

@article{CohenJacob1994,
abstract = {Statistical measures can't help you. Maybe meta analysis and power analysis a little. But mainly, it's about sensible testing, quantities, and replication.},
author = {{Cohen Jacob}},
file = {:C$\backslash$:/Users/Mike/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen J - 1994 - The Earth is round (p 0.05).pdf:pdf},
journal = {American Psychologist},
keywords = {hypothesis,p,reproducibility,significance,statistics},
mendeley-tags = {hypothesis,p,reproducibility,significance,statistics},
pages = {997--1003},
title = {{The Earth is round (p <0.05)}},
volume = {December},
year = {1994}
}
